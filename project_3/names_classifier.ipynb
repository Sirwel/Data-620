{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08a4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk import DecisionTreeClassifier, NaiveBayesClassifier, classify\n",
    "from nltk.classify import MaxentClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    accuracy_score, confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "nltk.download(\"names\", quiet=True)\n",
    "from IPython.display import display_html\n",
    "import re\n",
    "random.seed(46)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2517bf2",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ea63a",
   "metadata": {},
   "source": [
    "The goal of this experiment is to build a supervised classifier that can predict the gender of a given first name.  \n",
    "The task uses the *Names Corpus* from the **Natural Language Toolkit (NLTK)**, which contains approximately **7,900 English names**, each labeled as either *male* or *female*.  \n",
    "\n",
    "This exercise follows the workflow described in *Chapter 6* of *Natural Language Processing with Python*, where the objective is to:\n",
    "1. Train a model using labeled data.  \n",
    "2. Make incremental feature improvements guided by a development test (dev-test) set.  \n",
    "3. Evaluate the final model’s performance on an unseen test set.  \n",
    "\n",
    "Three classifiers are explored as described in the book:\n",
    "- **Naive Bayes Classifier**\n",
    "- **Decision Tree Classifier**\n",
    "- **Maximum Entropy (MaxEnt) Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655d786",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d228605",
   "metadata": {},
   "source": [
    "The *Names Corpus* is stored within NLTK under two files: `male.txt` and `female.txt`, each containing a list of names associated with the respective gender label.  \n",
    "\n",
    "To avoid ordering bias, the dataset was **randomly shuffled** using Python’s random module with a fixed seed for reproducibility.  \n",
    "The shuffled names were divided into three subsets:\n",
    "- **Training set (6,900 names)** — used to train the model.  \n",
    "- **Dev-test set (500 names)** — used during model development to test incremental improvements.  \n",
    "- **Test set (500 names)** — reserved for final evaluation after model tuning.\n",
    "\n",
    "To streamline the process, I created **helper functions** that handle both the random splitting of the data and the feature extraction.  \n",
    "Each helper function accepts a **feature function** as an argument, allowing the experiment to easily test different feature engineering strategies across multiple runs while maintaining consistent train/dev/test splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efefd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split():\n",
    "    data = [(n, \"male\") for n in names.words(\"male.txt\")] + \\\n",
    "           [(n, \"female\") for n in names.words(\"female.txt\")]\n",
    "    random.shuffle(data)\n",
    "    # 6900 train, 500 dev-test, 500 test\n",
    "    train, dev_test, test = data[:6900], data[6900:7400], data[7400:7900]\n",
    "    return train, dev_test, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67b2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_sets(data,gender_features):\n",
    "    return [(gender_features(n), g) for (n, g) in data]\n",
    "\n",
    "def train_models(train_set):\n",
    "    models = {\n",
    "        \"NaiveBayes\": NaiveBayesClassifier.train(train_set),\n",
    "        \"DecisionTree\": DecisionTreeClassifier.train(train_set),\n",
    "        \"MaxEnt\": MaxentClassifier.train(train_set, max_iter=50,trace=0)\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    y_true = [label for (_, label) in dataset]\n",
    "    y_pred = [model.classify(features) for (features, _) in dataset]\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, pos_label=\"female\")\n",
    "    rec = recall_score(y_true, y_pred, pos_label=\"female\")\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=\"female\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[\"female\", \"male\"])\n",
    "    TP, FN, FP, TN = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) else 0\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity\n",
    "    }\n",
    "\n",
    "def generate_report(models, dataset, round_digits=3):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        metrics = evaluate_model(model, dataset)\n",
    "        metrics[\"Model\"] = name\n",
    "        results.append(metrics)\n",
    "    df = pd.DataFrame(results).set_index(\"Model\").round(round_digits)\n",
    "    return df\n",
    "\n",
    "\n",
    "def display_side_by_side(dfs, titles=None):\n",
    "    html_str = \"<div style='display:flex;flex-flow:row nowrap;column-gap:10px'>\"\n",
    "    for df, title in zip(dfs, titles):\n",
    "        html_str += f\"\"\"\n",
    "        <div style=\"margin:10px\">\n",
    "            <h4 style=\"text-align:center\">{title}</h4>\n",
    "            {df.to_html()}\n",
    "        </div>\"\"\"\n",
    "    html_str += \"</div>\"\n",
    "\n",
    "    display_html(html_str, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d95dca",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1cd48",
   "metadata": {},
   "source": [
    "\n",
    "Three supervised classifiers were trained using NLTK’s implementations: **Naive Bayes**, **Decision Tree**, and **Maximum Entropy (MaxEnt)**. All models were trained on the **training set (6,900 names)**, validated on the **dev-test set (500 names)** for incremental improvements, and later evaluated on the **test set (500 names)** for final performance.\n",
    "\n",
    "Each experiment uses a helper function, `train_models()`, to train all classifiers consistently. Model performance is evaluated using the following metrics:\n",
    "\n",
    "| Metric | Description |\n",
    "|---------|--------------|\n",
    "| **Accuracy** | Overall proportion of correct predictions |\n",
    "| **Precision** | Proportion of positive predictions that were correct |\n",
    "| **Recall** | Proportion of actual positives correctly identified |\n",
    "| **F1** | Harmonic mean of Precision and Recall |\n",
    "| **Sensitivity** | True positive rate for the positive class (female) |\n",
    "| **Specificity** | True negative rate for the negative class (male) |\n",
    "\n",
    "All metrics are reported per experiment in tabular form for the **training**, **dev-test**, and **test** sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cc026",
   "metadata": {},
   "source": [
    "### 3.1 *Experiement 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f574ed",
   "metadata": {},
   "source": [
    "In this experiment, I use four simple linguistic features derived from each name: the **first letter**, **last letter**, **name length**, and whether the name **ends with a vowel**. These features capture common gender patterns in names. For instance, many female names tend to end with vowels, while male names often end with consonants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe884d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name = name.lower()\n",
    "    vowels = set(\"aeiou\")\n",
    "\n",
    "    return {\n",
    "        \"last_letter\": name[-1],\n",
    "        \"first_letter\": name[0],\n",
    "        \"length\": len(name),\n",
    "        \"ends_with_vowel\": name[-1] in vowels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5f2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:flex;flex-flow:row nowrap;column-gap:10px'>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Training Set (Exp 1)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Dev Set (Exp 1)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Test Set (Exp 1)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(45)\n",
    "\n",
    "train, dev_test, test = load_and_split()\n",
    "train_set, dev_test_set, test_set = map( lambda data : make_sets(data,gender_features), [train, dev_test, test])\n",
    "\n",
    "models = train_models(train_set)\n",
    "# Run each separately if you want:\n",
    "train_report = generate_report(models, train_set)\n",
    "dev_report = generate_report(models, dev_test_set)\n",
    "test_report = generate_report(models, test_set)\n",
    "\n",
    "datasets_r1 = [train_report,test_report,dev_report]\n",
    "r1_labels = [\"Training Set (Exp 1)\",\"Dev Set (Exp 1)\", \"Test Set (Exp 1)\"]\n",
    "display_side_by_side(datasets_r1,r1_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb519cde",
   "metadata": {},
   "source": [
    "\n",
    "The **Naive Bayes** model had accuracy around **0.75** on the training set, **0.74** on the dev set, and **0.73** on the test set. It predicts female names correctly most of the time, but its recall shows it still misses some. The difference between its training and test results is small, which means it’s stable but not the most accurate.  \n",
    "\n",
    "The **Decision Tree** model reached the highest training accuracy at **0.84**, but that dropped to **0.73** on the dev set and **0.78** on the test set. It finds most female names correctly but also mistakes many male names as female. The gap between its training and evaluation results shows it learned patterns too specific to the training data.  \n",
    "\n",
    "The **Maximum Entropy** model stayed balanced and consistent across all three sets. Its accuracy was about **0.79** on training, **0.74** on the dev set, and **0.76** on the test set. Both its recall and precision remained strong, meaning it recognizes female names accurately without making many false predictions.  \n",
    "\n",
    "Among the three models, the **Maximum Entropy** classifier performed the best overall. It achieved a good balance between accuracy, recall, and precision, while remaining stable across all datasets.  \n",
    "\n",
    "As the next step, additional experiments will be performed to test new feature combinations and see if the overall metrics can be improved further.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf8cc2",
   "metadata": {},
   "source": [
    "### 3.2 *Experiment 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868f169",
   "metadata": {},
   "source": [
    "In this experiment, we keep the features from Experiment One and add new ones to better describe the sound and structure of names. The **last two letters** help detect common endings that may relate to gender, such as “-na” or “-us.” The **presence of “y”** (`has_y`) captures names that often differ by gender, like “Mary” or “Tony.” The **double letter** feature (`has_double`) looks for repeated letters (like “ll” in “Allison”), which can be more common in certain names. Lastly, the **vowel** and **consonant counts** show how many of each type of letter a name has, helping the model notice sound patterns that may differ between male and female names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0644e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    name = name.lower()\n",
    "    vowels = set(\"aeiou\")\n",
    "    vcount = sum(c in vowels for c in name)\n",
    "    ccount = sum(c.isalpha() and c not in vowels for c in name)\n",
    "\n",
    "    return {\n",
    "        \"last_letter\": name[-1],\n",
    "        \"last_two\": name[-2:],\n",
    "        \"first_letter\": name[0],\n",
    "        \"length\": len(name),\n",
    "        \"ends_with_vowel\": name[-1] in vowels,\n",
    "                \n",
    "        'has_y': 'y' in name,\n",
    "        'has_double': any(a == b for a, b in zip(name, name[1:])),\n",
    "        \"vowel_count\": vcount,\n",
    "        \"consonant_count\": ccount,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9263f06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:flex;flex-flow:row nowrap;column-gap:10px'>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Training Set (Exp 2)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Dev-test Set (Exp 2)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Test Set (Exp 2)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.780</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- Experiment Two -----\n",
    "random.seed(455)\n",
    "exp2_train, exp2_dev_test, exp2_test = load_and_split()\n",
    "exp2_train_set, exp2_dev_test_set, exp2_test_set = map(lambda data : make_sets(data,gender_features2), [exp2_train, exp2_dev_test, exp2_test])\n",
    "\n",
    "exp2_models = train_models(exp2_train_set)\n",
    "\n",
    "exp2_train_report = generate_report(exp2_models, exp2_train_set)\n",
    "exp2_dev_report = generate_report(exp2_models, exp2_dev_test_set)\n",
    "exp2_test_report = generate_report(exp2_models, exp2_test_set)\n",
    "\n",
    "exp2_datasets = [exp2_train_report, exp2_dev_report, exp2_test_report]\n",
    "exp2_labels = [\"Training Set (Exp 2)\", \"Dev-test Set (Exp 2)\", \"Test Set (Exp 2)\"]\n",
    "\n",
    "display_side_by_side(exp2_datasets, exp2_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51711370",
   "metadata": {},
   "source": [
    "In Experiment Two, adding new features improved performance on both the training and test sets. On the **training set**, the **Decision Tree** reached the best results with an **accuracy of 0.919**, **recall of 0.955**, and **F1-score of 0.937**, showing that it learned the training data very well. However, this near-perfect performance also suggests some overfitting. The **MaxEnt model** achieved a good balance with an **accuracy of 0.827**, **precision of 0.846**, and **recall of 0.887**, showing it can make accurate predictions without memorizing the data. The **Naive Bayes** model improved slightly, reaching an **accuracy of 0.765**, but its **recall (0.741)** was still lower than the other models.  \n",
    "\n",
    "On the **test set**, the **MaxEnt model** gave the strongest results overall, with an **accuracy of 0.818**, **recall of 0.880**, and **F1-score of 0.863**. This shows it generalized well to unseen data. The **Decision Tree**, while slightly less accurate (**0.772**), still performed strongly but showed signs of overfitting because its recall dropped from 0.955 to 0.831. The **Naive Bayes** model stayed consistent, improving slightly to **accuracy 0.774**, but it continued to lag behind in recall and sensitivity.  \n",
    "\n",
    "In short, the new features helped all models learn better patterns. The **Decision Tree** learned the training data best but did not generalize as well. The **MaxEnt model** showed the best overall balance, performing well on both training and test sets. The **Naive Bayes** model remained stable but less powerful. The **dev-test results** confirmed these trends, showing that MaxEnt remained the most reliable model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b1a38",
   "metadata": {},
   "source": [
    "### 3.3 *Experiment 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3103860",
   "metadata": {},
   "source": [
    "In this experiment, we keep all the features from Experiment Two and add new ones to capture the rhythm and sound structure of names in more detail. The **vowel ratio** measures how many vowels appear compared to the total length of the name. This helps identify smoother or softer-sounding names, which are sometimes linked to gender patterns. The **syllables** feature estimates how many vowel groups the name contains, giving an idea of how complex or long the name sounds when spoken.  \n",
    "\n",
    "We also include three new features that look at how the name ends: **ends_liquid**, **ends_nasal**, and **ends_sibilant**. These features check whether the last letter is part of certain sound types—like “l” or “r” for liquids, “m” or “n” for nasals, and “s” or “z” for sibilants. These endings often carry subtle sound patterns that can differ across male and female names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b106e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(name):\n",
    "    name = name.lower()\n",
    "\n",
    "    vowels = set(\"aeiou\")\n",
    "    vcount = sum(c in vowels for c in name)\n",
    "    ccount = sum(c.isalpha() and c not in vowels for c in name)\n",
    "    v = set(\"aeiou\")\n",
    "    liquid = set(\"lr\")\n",
    "    nasal  = set(\"mn\")\n",
    "    sibil  = set(\"szcxj\")  # crude\n",
    "\n",
    "    return {\n",
    "        \"last_letter\": name[-1],\n",
    "        \"last_two\": name[-2:],\n",
    "        \"first_letter\": name[0],\n",
    "        \"length\": len(name),\n",
    "        \"ends_with_vowel\": name[-1] in \"aeiou\",\n",
    "                \n",
    "        'has_y': 'y' in name,\n",
    "        'has_double': any(a == b for a, b in zip(name, name[1:])),\n",
    "        \"vowel_count\": vcount,\n",
    "        \"consonant_count\": ccount,\n",
    "        \n",
    "        \n",
    "        \"vowel_ratio\": vcount / max(1, len(name)),\n",
    "        \"syllables\":len(re.findall(r\"[aeiouy]+\", name)) ,\n",
    "        \"ends_liquid\": name[-1] in liquid,\n",
    "        \"ends_nasal\": name[-1] in nasal,\n",
    "        \"ends_sibilant\": name[-1] in sibil\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae97bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display:flex;flex-flow:row nowrap;column-gap:10px'>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Training Set (Exp 3)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Dev-test Set (Exp 3)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.784</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div style=\"margin:10px\">\n",
       "            <h4 style=\"text-align:center\">Test Set (Exp 3)</h4>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxEnt</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- Experiment Three -----\n",
    "random.seed(455)\n",
    "exp3_train, exp3_dev_test, exp3_test = load_and_split()\n",
    "exp3_train_set, exp3_dev_test_set, exp3_test_set = map(\n",
    "    lambda data: make_sets(data, gender_features3),\n",
    "    [exp3_train, exp3_dev_test, exp3_test]\n",
    ")\n",
    "\n",
    "exp3_models = train_models(exp3_train_set)\n",
    "\n",
    "exp3_train_report = generate_report(exp3_models, exp3_train_set)\n",
    "exp3_dev_report = generate_report(exp3_models, exp3_dev_test_set)\n",
    "exp3_test_report = generate_report(exp3_models, exp3_test_set)\n",
    "\n",
    "exp3_datasets = [exp3_train_report, exp3_dev_report, exp3_test_report]\n",
    "exp3_labels = [\"Training Set (Exp 3)\", \"Dev-test Set (Exp 3)\", \"Test Set (Exp 3)\"]\n",
    "\n",
    "display_side_by_side(exp3_datasets, exp3_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87178c83",
   "metadata": {},
   "source": [
    "In Experiment Three, the new sound-based features slightly improved the overall results, especially for the MaxEnt model. On the **training set**, the **Decision Tree** again performed the best with an **accuracy of 0.920**, **recall of 0.956**, and **F1-score of 0.938**, showing that it continued to fit the training data very closely. However, this high performance also suggests that it may still be overfitting. The **MaxEnt model** remained consistent, with an **accuracy of 0.827**, **precision of 0.846**, and **recall of 0.886**, confirming that it balances accuracy and generalization well. The **Naive Bayes** model scored slightly lower, with **accuracy 0.758** and **F1-score 0.793**, indicating that the new features did not significantly improve its learning ability.  \n",
    "\n",
    "On the **test set**, the **MaxEnt model** again achieved the best performance, reaching an **accuracy of 0.820**, **precision of 0.851**, **recall of 0.877**, and **F1-score of 0.864**. These results show that the additional features such as **vowel ratio**, **syllable count**, and sound-ending indicators helped the model better understand name structure. The **Decision Tree** followed closely, with an **accuracy of 0.776** and an **F1-score of 0.829**, maintaining solid results but still showing a drop in performance compared to the training set. The **Naive Bayes** model stayed consistent, reaching **accuracy 0.764** and **F1-score 0.805**, but remained the weakest overall.  \n",
    "\n",
    "We can say that the new sound-related features improved model understanding of name patterns without overcomplicating the data. The **MaxEnt model** continued to be the best performer, showing high and stable results across the training and test sets. The **Decision Tree** kept its strong training performance but overfitted slightly, while **Naive Bayes** remained simple and steady but less effective overall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b637b",
   "metadata": {},
   "source": [
    "## 4. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc53d3",
   "metadata": {},
   "source": [
    "After comparing all three experiments, **Experiment Two** produced the best overall model, offering a strong balance between accuracy, precision, recall, sensitivity, and specificity.  \n",
    "\n",
    "In **Experiment One**, the models used only basic features like the first and last letters, which gave modest results but lacked depth. The **MaxEnt model** already showed balanced precision and recall, but the models in general had lower sensitivity and specificity, meaning they were not yet good at correctly identifying both male and female names.  \n",
    "\n",
    "In **Experiment Two**, the addition of vowel and consonant counts, double letters, and the presence of “y” led to clear improvements. The **MaxEnt model** achieved an **accuracy of 0.818**, **precision of 0.847**, **recall (sensitivity) of 0.880**, and **specificity of 0.701** on the test set. This means it correctly identified 88% of positive cases and 70% of negative ones, showing it handled both classes fairly well. The **Decision Tree** reached similar accuracy (**0.772**) but had lower specificity (**0.661**), showing it was slightly biased toward one class. The **Naive Bayes** model was consistent but less balanced, with **sensitivity 0.748** and **specificity 0.822**, meaning it caught most positives but made more mistakes on negatives.  \n",
    "\n",
    "In **Experiment Three**, new features such as vowel ratio, syllable count, and sound-ending types produced only small improvements. The **MaxEnt model** slightly increased its **accuracy to 0.820** and **precision to 0.851**, but **sensitivity (0.877)** and **specificity (0.713)** stayed almost the same. These small gains suggest that the added complexity did not significantly change how well the model identified names from both classes.  \n",
    "\n",
    "Overall, **Experiment Two** gave the most balanced and generalizable results. The **MaxEnt model** from this experiment performed well on all key metrics, showing high accuracy, precision, recall, and stable sensitivity and specificity without signs of overfitting. It remains the best and most reliable model across all experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537197e",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289df776",
   "metadata": {},
   "source": [
    "Across the three experiments, performance improved as new features were added, but the most meaningful gains occurred in **Experiment Two**. The new features in that round, such as vowel and consonant counts, double letters, and the presence of “y,” gave the models a better understanding of structural and sound patterns in names. This improvement was clear in the **MaxEnt model**, which reached an **accuracy of 0.818**, **precision of 0.847**, **recall (sensitivity) of 0.880**, and **specificity of 0.701** on the test set. These results show that the model performed well on both positive and negative classifications while maintaining good balance across all metrics.  \n",
    "\n",
    "In **Experiment Three**, additional sound-based features like vowel ratio and syllable count brought only minor improvements. The **MaxEnt model** again achieved the best results, but the increase in performance was small compared to the added complexity. This suggests that the model had already captured most of the useful information from the simpler features in Experiment Two.  \n",
    "\n",
    "Overall, **Experiment Two** produced the most balanced and reliable model. The **MaxEnt classifier** showed strong accuracy, high recall, and stable sensitivity and specificity without overfitting. The findings highlight that a carefully chosen set of linguistic and structural features can provide strong predictive performance without unnecessary complexity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
