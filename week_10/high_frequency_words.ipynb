{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib import request\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score,\n",
        "    accuracy_score, confusion_matrix\n",
        ")\n",
        "from gensim.models import Word2Vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The IMDB Dataset is a widely recognized benchmark in natural language processing, primarily used for document classification and sentiment analysis. It comprises a large collection of movie reviews from the Internet Movie Database (IMDB), each labeled as either positive or negative, providing a balanced and well-structured corpus for analyzing text-based sentiment.\n",
        "\n",
        "This dataset enables the development and evaluation of machine learning models that classify textual content based on emotional tone or opinion. Its diversity in writing style, vocabulary, and sentiment intensity makes it suitable for testing both traditional algorithms, such as Logistic Regression and Naïve Bayes, and advanced deep learning architectures like Recurrent Neural Networks and Transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each movie review was cleaned to remove noise and ensure consistency. The text was converted to lowercase, HTML tags and punctuation were removed, and extra spaces were collapsed.  \n",
        "The cleaned text was stored in a new column called **clean_review**. Sentiment labels were also converted from **“positive”** and **“negative”** to binary values (**1** and **0**, respectively) to prepare the data for machine learning classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies_df = pd.read_csv(\"IMDB Dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)       # remove HTML tags\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)    # remove punctuation/numbers\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip() # collapse spaces\n",
        "    return text\n",
        "\n",
        "movies_df[\"clean_review\"] = movies_df[\"review\"].apply(clean_text)\n",
        "movies_df[\"label\"] = movies_df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>a wonderful little production the filming tech...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically there s a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei s love in the time of money is a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                        clean_review  label  \n",
              "0  one of the other reviewers has mentioned that ...      1  \n",
              "1  a wonderful little production the filming tech...      1  \n",
              "2  i thought this was a wonderful way to spend ti...      1  \n",
              "3  basically there s a family where a little boy ...      0  \n",
              "4  petter mattei s love in the time of money is a...      1  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train,x_test, y_train,y_test = train_test_split(\n",
        "    movies_df[\"clean_review\"],\n",
        "    movies_df[\"label\"],\n",
        "    train_size=0.8,\n",
        "    test_size=0.2, \n",
        "    random_state=456,\n",
        "    stratify=movies_df[\"label\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vectorizer = TfidfVectorizer(max_features=5000,stop_words=\"english\",ngram_range=(1,4))\n",
        "# v_train_set = vectorizer.fit_transform(x_train)\n",
        "# v_test_set =  vectorizer.fit_transform(x_test)\n",
        "x_train_tokens = [text.split() for text in x_train]\n",
        "x_test_tokens  = [text.split() for text in x_test]\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=x_train_tokens,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4,\n",
        "    sg=1\n",
        ")\n",
        "\n",
        "def document_vector(words):\n",
        "    words = [w for w in words if w in w2v_model.wv]\n",
        "    if len(words) == 0:\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "    return np.mean(w2v_model.wv[words], axis=0)\n",
        "\n",
        "v_train_set = np.vstack([document_vector(words) for words in x_train_tokens])\n",
        "v_test_set  = np.vstack([document_vector(words) for words in x_test_tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.12770022,  0.14132889,  0.00443909, ..., -0.13852431,\n",
              "         0.02057929, -0.14643483],\n",
              "       [-0.14634496,  0.16588333,  0.03190178, ..., -0.157649  ,\n",
              "        -0.02352808, -0.13709491],\n",
              "       [-0.16994557,  0.15071285,  0.05862762, ..., -0.1477762 ,\n",
              "         0.01954959, -0.08624883],\n",
              "       ...,\n",
              "       [-0.11269318,  0.23411827, -0.02945689, ..., -0.12321492,\n",
              "         0.08264293, -0.09171139],\n",
              "       [-0.13498987,  0.1477674 ,  0.02775964, ..., -0.16479829,\n",
              "        -0.02493664, -0.11860866],\n",
              "       [-0.13356303,  0.14362587,  0.04662751, ..., -0.14539264,\n",
              "         0.00798832, -0.08886444]], shape=(10000, 100), dtype=float32)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_metrics = [\n",
        "        \"Set\",\n",
        "        \"Accuracy\",\n",
        "        \"Precision\",\n",
        "        \"Recall\",\n",
        "        \"Sensitivity\",\n",
        "        \"Specificity\",\n",
        "        \"F1\"\n",
        "        ]\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "   \n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TP, FN, FP, TN = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) else 0\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"Sensitivity\": sensitivity,\n",
        "        \"Specificity\": specificity,\n",
        "        \"F1\": f1\n",
        "    }\n",
        "    \n",
        "def generate_report(model_instance,trainX,trainY,testX,testY):\n",
        "    y_train_pred = model_instance.predict(trainX)\n",
        "    y_test_pred = model_instance.predict(testX)\n",
        "    train_set_metrics = evaluate_model(trainY,y_train_pred)\n",
        "    test_set_metrics = evaluate_model(testY,y_test_pred)\n",
        "    train_set_metrics[\"Set\"] = \"Training\"\n",
        "    test_set_metrics[\"Set\"] = \"Test\"\n",
        "    model_metrics_df = pd.DataFrame(columns=model_metrics,data= [train_set_metrics,test_set_metrics])\n",
        "    styled_report = model_metrics_df.style.hide(axis=\"index\")\n",
        "    return model_metrics_df,styled_report\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': np.float64(0.15399999999999997)}\n",
            "Best CV Accuracy: 0.883\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_430f8\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_430f8_level0_col0\" class=\"col_heading level0 col0\" >Set</th>\n",
              "      <th id=\"T_430f8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_430f8_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
              "      <th id=\"T_430f8_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_430f8_level0_col4\" class=\"col_heading level0 col4\" >Sensitivity</th>\n",
              "      <th id=\"T_430f8_level0_col5\" class=\"col_heading level0 col5\" >Specificity</th>\n",
              "      <th id=\"T_430f8_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_430f8_row0_col0\" class=\"data row0 col0\" >Training</td>\n",
              "      <td id=\"T_430f8_row0_col1\" class=\"data row0 col1\" >0.917350</td>\n",
              "      <td id=\"T_430f8_row0_col2\" class=\"data row0 col2\" >0.909608</td>\n",
              "      <td id=\"T_430f8_row0_col3\" class=\"data row0 col3\" >0.926800</td>\n",
              "      <td id=\"T_430f8_row0_col4\" class=\"data row0 col4\" >0.907900</td>\n",
              "      <td id=\"T_430f8_row0_col5\" class=\"data row0 col5\" >0.926800</td>\n",
              "      <td id=\"T_430f8_row0_col6\" class=\"data row0 col6\" >0.918124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_430f8_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
              "      <td id=\"T_430f8_row1_col1\" class=\"data row1 col1\" >0.575900</td>\n",
              "      <td id=\"T_430f8_row1_col2\" class=\"data row1 col2\" >0.574136</td>\n",
              "      <td id=\"T_430f8_row1_col3\" class=\"data row1 col3\" >0.587800</td>\n",
              "      <td id=\"T_430f8_row1_col4\" class=\"data row1 col4\" >0.564000</td>\n",
              "      <td id=\"T_430f8_row1_col5\" class=\"data row1 col5\" >0.587800</td>\n",
              "      <td id=\"T_430f8_row1_col6\" class=\"data row1 col6\" >0.580887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x753e1dee30e0>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {'C': np.arange(0.001, 1, 0.009)}\n",
        "\n",
        "\n",
        "svm_model = LinearSVC(random_state=500)\n",
        "\n",
        "grid = GridSearchCV(svm_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "grid.fit(v_train_set, y_train)\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best CV Accuracy:\", round(grid.best_score_, 3))\n",
        "svm_model = grid.best_estimator_\n",
        "\n",
        "svm_df, svm_df_styled = generate_report(svm_model,v_train_set,y_train,v_test_set,y_test)\n",
        "svm_df_styled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lewris/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': np.float64(0.986), 'solver': 'liblinear'}\n",
            "Best CV Accuracy: 0.884\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_7b138\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_7b138_level0_col0\" class=\"col_heading level0 col0\" >Set</th>\n",
              "      <th id=\"T_7b138_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_7b138_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
              "      <th id=\"T_7b138_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_7b138_level0_col4\" class=\"col_heading level0 col4\" >Sensitivity</th>\n",
              "      <th id=\"T_7b138_level0_col5\" class=\"col_heading level0 col5\" >Specificity</th>\n",
              "      <th id=\"T_7b138_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_7b138_row0_col0\" class=\"data row0 col0\" >Training</td>\n",
              "      <td id=\"T_7b138_row0_col1\" class=\"data row0 col1\" >0.911500</td>\n",
              "      <td id=\"T_7b138_row0_col2\" class=\"data row0 col2\" >0.904065</td>\n",
              "      <td id=\"T_7b138_row0_col3\" class=\"data row0 col3\" >0.920700</td>\n",
              "      <td id=\"T_7b138_row0_col4\" class=\"data row0 col4\" >0.902300</td>\n",
              "      <td id=\"T_7b138_row0_col5\" class=\"data row0 col5\" >0.920700</td>\n",
              "      <td id=\"T_7b138_row0_col6\" class=\"data row0 col6\" >0.912307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_7b138_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
              "      <td id=\"T_7b138_row1_col1\" class=\"data row1 col1\" >0.576400</td>\n",
              "      <td id=\"T_7b138_row1_col2\" class=\"data row1 col2\" >0.598454</td>\n",
              "      <td id=\"T_7b138_row1_col3\" class=\"data row1 col3\" >0.464400</td>\n",
              "      <td id=\"T_7b138_row1_col4\" class=\"data row1 col4\" >0.688400</td>\n",
              "      <td id=\"T_7b138_row1_col5\" class=\"data row1 col5\" >0.464400</td>\n",
              "      <td id=\"T_7b138_row1_col6\" class=\"data row1 col6\" >0.522973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x753e1e9ecf80>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "param_grid = {'C': np.arange(0.001, 1, 0.005), 'solver': ['liblinear', 'lbfgs']}\n",
        "\n",
        "grid = GridSearchCV(estimator=log_reg, param_grid=param_grid,cv=5, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "\n",
        "grid.fit(v_train_set, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best CV Accuracy:\", round(grid.best_score_, 3))\n",
        "\n",
        "logistic_model = grid.best_estimator_\n",
        "\n",
        "lgreg_df, lgreg_df_styled = generate_report(logistic_model,v_train_set,y_train,v_test_set,y_test)\n",
        "lgreg_df_styled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_81515\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_81515_level0_col0\" class=\"col_heading level0 col0\" >Set</th>\n",
              "      <th id=\"T_81515_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_81515_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
              "      <th id=\"T_81515_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_81515_level0_col4\" class=\"col_heading level0 col4\" >Sensitivity</th>\n",
              "      <th id=\"T_81515_level0_col5\" class=\"col_heading level0 col5\" >Specificity</th>\n",
              "      <th id=\"T_81515_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_81515_row0_col0\" class=\"data row0 col0\" >Training</td>\n",
              "      <td id=\"T_81515_row0_col1\" class=\"data row0 col1\" >0.863900</td>\n",
              "      <td id=\"T_81515_row0_col2\" class=\"data row0 col2\" >0.853541</td>\n",
              "      <td id=\"T_81515_row0_col3\" class=\"data row0 col3\" >0.878550</td>\n",
              "      <td id=\"T_81515_row0_col4\" class=\"data row0 col4\" >0.849250</td>\n",
              "      <td id=\"T_81515_row0_col5\" class=\"data row0 col5\" >0.878550</td>\n",
              "      <td id=\"T_81515_row0_col6\" class=\"data row0 col6\" >0.865865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_81515_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
              "      <td id=\"T_81515_row1_col1\" class=\"data row1 col1\" >0.580400</td>\n",
              "      <td id=\"T_81515_row1_col2\" class=\"data row1 col2\" >0.579259</td>\n",
              "      <td id=\"T_81515_row1_col3\" class=\"data row1 col3\" >0.587600</td>\n",
              "      <td id=\"T_81515_row1_col4\" class=\"data row1 col4\" >0.573200</td>\n",
              "      <td id=\"T_81515_row1_col5\" class=\"data row1 col5\" >0.587600</td>\n",
              "      <td id=\"T_81515_row1_col6\" class=\"data row1 col6\" >0.583400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ac554527770>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_model = MultinomialNB()\n",
        "naive_model.fit(v_train_set,y_train)\n",
        "naive_df, naive_df_styled = generate_report(naive_model,v_train_set,y_train,v_test_set,y_test)\n",
        "naive_df_styled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 500}\n",
            "Best CV Accuracy: 0.867\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_9c495\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_9c495_level0_col0\" class=\"col_heading level0 col0\" >Set</th>\n",
              "      <th id=\"T_9c495_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_9c495_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
              "      <th id=\"T_9c495_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_9c495_level0_col4\" class=\"col_heading level0 col4\" >Sensitivity</th>\n",
              "      <th id=\"T_9c495_level0_col5\" class=\"col_heading level0 col5\" >Specificity</th>\n",
              "      <th id=\"T_9c495_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_9c495_row0_col0\" class=\"data row0 col0\" >Training</td>\n",
              "      <td id=\"T_9c495_row0_col1\" class=\"data row0 col1\" >0.961775</td>\n",
              "      <td id=\"T_9c495_row0_col2\" class=\"data row0 col2\" >0.953588</td>\n",
              "      <td id=\"T_9c495_row0_col3\" class=\"data row0 col3\" >0.970800</td>\n",
              "      <td id=\"T_9c495_row0_col4\" class=\"data row0 col4\" >0.952750</td>\n",
              "      <td id=\"T_9c495_row0_col5\" class=\"data row0 col5\" >0.970800</td>\n",
              "      <td id=\"T_9c495_row0_col6\" class=\"data row0 col6\" >0.962117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_9c495_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
              "      <td id=\"T_9c495_row1_col1\" class=\"data row1 col1\" >0.553100</td>\n",
              "      <td id=\"T_9c495_row1_col2\" class=\"data row1 col2\" >0.542096</td>\n",
              "      <td id=\"T_9c495_row1_col3\" class=\"data row1 col3\" >0.683800</td>\n",
              "      <td id=\"T_9c495_row1_col4\" class=\"data row1 col4\" >0.422400</td>\n",
              "      <td id=\"T_9c495_row1_col5\" class=\"data row1 col5\" >0.683800</td>\n",
              "      <td id=\"T_9c495_row1_col6\" class=\"data row1 col6\" >0.604758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x753e1815a4e0>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "xgboost = GradientBoostingClassifier(random_state=500)\n",
        "param_grid = {'n_estimators':[100,500],'learning_rate':[0.01,0.1,0.2],'max_depth':[2,3,4]}\n",
        "grid = GridSearchCV(xgboost,param_grid,cv=3,scoring='accuracy',n_jobs=-1,verbose=0)\n",
        "grid.fit(v_train_set,y_train)\n",
        "print(\"Best Params:\",grid.best_params_)\n",
        "print(\"Best CV Accuracy:\",round(grid.best_score_,3))\n",
        "xgboost = grid.best_estimator_\n",
        "\n",
        "naxgboost_df, xgboost_df_styled = generate_report(xgboost,v_train_set,y_train,v_test_set,y_test)\n",
        "xgboost_df_styled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_c004f\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_c004f_level0_col0\" class=\"col_heading level0 col0\" >Set</th>\n",
              "      <th id=\"T_c004f_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_c004f_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
              "      <th id=\"T_c004f_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_c004f_level0_col4\" class=\"col_heading level0 col4\" >Sensitivity</th>\n",
              "      <th id=\"T_c004f_level0_col5\" class=\"col_heading level0 col5\" >Specificity</th>\n",
              "      <th id=\"T_c004f_level0_col6\" class=\"col_heading level0 col6\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_c004f_row0_col0\" class=\"data row0 col0\" >Training</td>\n",
              "      <td id=\"T_c004f_row0_col1\" class=\"data row0 col1\" >1.000000</td>\n",
              "      <td id=\"T_c004f_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
              "      <td id=\"T_c004f_row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
              "      <td id=\"T_c004f_row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
              "      <td id=\"T_c004f_row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
              "      <td id=\"T_c004f_row0_col6\" class=\"data row0 col6\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_c004f_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
              "      <td id=\"T_c004f_row1_col1\" class=\"data row1 col1\" >0.584100</td>\n",
              "      <td id=\"T_c004f_row1_col2\" class=\"data row1 col2\" >0.593299</td>\n",
              "      <td id=\"T_c004f_row1_col3\" class=\"data row1 col3\" >0.534800</td>\n",
              "      <td id=\"T_c004f_row1_col4\" class=\"data row1 col4\" >0.633400</td>\n",
              "      <td id=\"T_c004f_row1_col5\" class=\"data row1 col5\" >0.534800</td>\n",
              "      <td id=\"T_c004f_row1_col6\" class=\"data row1 col6\" >0.562533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ac554525f70>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_forest = RandomForestClassifier(random_state=500)\n",
        "random_forest.fit(v_train_set,y_train)\n",
        "random_forest_df, random_forest_df_styled = generate_report(random_forest,v_train_set,y_train,v_test_set,y_test)\n",
        "random_forest_df_styled"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
